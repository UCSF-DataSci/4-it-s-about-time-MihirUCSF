{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Exploration and Preprocessing\n",
    "\n",
    "In this notebook, you will implement functions to load, preprocess, and visualize physiological data from the Wearable Exam Stress Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Implement the `load_data` function to read and organize the physiological data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='data'):\n",
    "    all_data = []\n",
    "    \n",
    "    subject_dirs = [d for d in Path(data_dir).iterdir() if d.is_dir() and d.name.startswith('S')]\n",
    "\n",
    "    # Read grades file with proper encoding\n",
    "    grades_path = Path(data_dir) / 'StudentGrades.txt'\n",
    "    \n",
    "    # Common encodings to try\n",
    "    encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
    "    grades = None\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            grades = pd.read_csv(grades_path, sep='\\t', encoding=encoding)\n",
    "            print(f\"Successfully read grades file using {encoding} encoding\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to read with {encoding} encoding, trying another...\")\n",
    "    \n",
    "    if grades is None:\n",
    "        print(\"Could not read grades file with any of the attempted encodings.\")\n",
    "\n",
    "    for subject_dir in subject_dirs:\n",
    "        subject_id = subject_dir.name\n",
    "        \n",
    "        # process each session (Midterm1, Midterm2, Final)\n",
    "        for session_name in ['Midterm 1', 'Midterm 2', 'Final']:\n",
    "            session_dir = subject_dir / session_name\n",
    "            \n",
    "            if not session_dir.exists():\n",
    "                continue\n",
    "                \n",
    "            # load heart rate data (BVP.csv)\n",
    "            bvp_file = session_dir / 'BVP.csv'\n",
    "            if bvp_file.exists():\n",
    "                bvp_data = pd.read_csv(bvp_file, header=None, names=['bvp'])\n",
    "                bvp_data['timestamp'] = pd.date_range(\n",
    "                    start='2023-01-01', \n",
    "                    periods=len(bvp_data), \n",
    "                    freq='64ms'  # BVP sampled at 64 Hz\n",
    "                )\n",
    "                \n",
    "            # load heart rate data (HR.csv)\n",
    "            hr_file = session_dir / 'HR.csv'\n",
    "            if hr_file.exists():\n",
    "                hr_data = pd.read_csv(hr_file, header=None, names=['heart_rate'])\n",
    "                hr_data['timestamp'] = pd.date_range(\n",
    "                    start='2023-01-01', \n",
    "                    periods=len(hr_data), \n",
    "                    freq='1s' \n",
    "                )\n",
    "                \n",
    "            # load EDA data\n",
    "            eda_file = session_dir / 'EDA.csv'\n",
    "            if eda_file.exists():\n",
    "                eda_data = pd.read_csv(eda_file, header=None, names=['eda'])\n",
    "                eda_data['timestamp'] = pd.date_range(\n",
    "                    start='2023-01-01', \n",
    "                    periods=len(eda_data), \n",
    "                    freq='250ms'  \n",
    "                )\n",
    "                \n",
    "            # load temperature data\n",
    "            temp_file = session_dir / 'TEMP.csv'\n",
    "            if temp_file.exists():\n",
    "                temp_data = pd.read_csv(temp_file, header=None, names=['temperature'])\n",
    "                temp_data['timestamp'] = pd.date_range(\n",
    "                    start='2023-01-01', \n",
    "                    periods=len(temp_data), \n",
    "                    freq='250ms' \n",
    "                )\n",
    "                \n",
    "            # resample all data to the same frequency\n",
    "            hr_resampled = hr_data.set_index('timestamp')\n",
    "            eda_resampled = eda_data.set_index('timestamp').resample('1s').mean()\n",
    "            temp_resampled = temp_data.set_index('timestamp').resample('1s').mean()\n",
    "            \n",
    "            # merge data into a single DataFrame\n",
    "            session_data = pd.concat([\n",
    "                hr_resampled, \n",
    "                eda_resampled,\n",
    "                temp_resampled\n",
    "            ], axis=1).reset_index()\n",
    "            \n",
    "            # add subject and session information\n",
    "            session_data['subject_id'] = subject_id\n",
    "            session_data['session'] = session_name\n",
    "            \n",
    "            all_data.append(session_data)\n",
    "    \n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory exists: True\n",
      "Found 10 subject directories: ['S1', 'S10', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9']\n",
      "Grades file exists: True\n",
      "\n",
      "Checking structure for S1:\n",
      "  Sessions found: ['Final', 'Midterm 1', 'Midterm 2']\n",
      "  Files in Final: ['ACC.csv', 'BVP.csv', 'EDA.csv', 'HR.csv', 'IBI.csv', 'info.txt', 'tags.csv', 'TEMP.csv']\n"
     ]
    }
   ],
   "source": [
    "# data loading check\n",
    "data_dir = 'data'\n",
    "data_path = Path(data_dir)\n",
    "\n",
    "# check if the data directory exists\n",
    "print(f\"Data directory exists: {data_path.exists()}\")\n",
    "\n",
    "# check for student directories\n",
    "subject_dirs = [d for d in data_path.iterdir() if d.is_dir() and d.name.startswith('S')]\n",
    "print(f\"Found {len(subject_dirs)} subject directories: {[d.name for d in subject_dirs]}\")\n",
    "\n",
    "# check if grades file exists\n",
    "grades_path = data_path / 'StudentGrades.txt'\n",
    "print(f\"Grades file exists: {grades_path.exists()}\")\n",
    "\n",
    "# check one subject directory structure\n",
    "if subject_dirs:\n",
    "    sample_subject = subject_dirs[0]\n",
    "    print(f\"\\nChecking structure for {sample_subject.name}:\")\n",
    "    sessions = [d.name for d in sample_subject.iterdir() if d.is_dir()]\n",
    "    print(f\"  Sessions found: {sessions}\")\n",
    "    \n",
    "    # check files in first session\n",
    "    if sessions:\n",
    "        first_session = sample_subject / sessions[0]\n",
    "        files = [f.name for f in first_session.iterdir() if f.is_file()]\n",
    "        print(f\"  Files in {sessions[0]}: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Implement the `preprocess_data` function to clean and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, output_dir='data/processed'):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    # Use ffill() and bfill() instead of fillna(method='ffill')\n",
    "    processed_data = data.copy()\n",
    "    processed_data = processed_data.ffill().bfill()  # Updated to remove warning\n",
    "    \n",
    "    # Remove outliers (z-score > 3) for each numerical column\n",
    "    for col in ['heart_rate', 'eda', 'temperature']:\n",
    "        if col in processed_data.columns:\n",
    "            # Calculate z-scores\n",
    "            z_scores = stats.zscore(processed_data[col], nan_policy='omit')\n",
    "            # Identify outliers\n",
    "            outliers = np.abs(z_scores) > 3\n",
    "            # Replace outliers with NaN, then interpolate\n",
    "            processed_data.loc[outliers, col] = np.nan\n",
    "            processed_data[col] = processed_data[col].interpolate(method='linear')\n",
    "    \n",
    "    # Normalize data for better comparison\n",
    "    for col in ['heart_rate', 'eda', 'temperature']:\n",
    "        if col in processed_data.columns:\n",
    "            # Min-max normalization\n",
    "            min_val = processed_data[col].min()\n",
    "            max_val = processed_data[col].max()\n",
    "            processed_data[f'{col}_normalized'] = (processed_data[col] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Save processed data by subject and session\n",
    "    for subject in processed_data['subject_id'].unique():\n",
    "        for session in processed_data['session'].unique():\n",
    "            subset = processed_data[\n",
    "                (processed_data['subject_id'] == subject) & \n",
    "                (processed_data['session'] == session)\n",
    "            ]\n",
    "            \n",
    "            if not subset.empty:\n",
    "                filename = f\"{subject}_{session}_processed.csv\"\n",
    "                subset.to_csv(f\"{output_dir}/{filename}\", index=False)\n",
    "    \n",
    "    # Save the complete processed dataset\n",
    "    processed_data.to_csv(f\"{output_dir}/all_processed.csv\", index=False)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read with utf-8 encoding, trying another...\n",
      "Successfully read grades file using latin1 encoding\n",
      "Loaded data with shape: (443307, 6)\n",
      "Sample of loaded data:\n",
      "            timestamp    heart_rate           eda   temperature subject_id  \\\n",
      "0 2023-01-01 00:00:00  1.539435e+09  3.848588e+08  3.848589e+08         S1   \n",
      "1 2023-01-01 00:00:01  1.000000e+00  2.210425e-02  2.251000e+01         S1   \n",
      "2 2023-01-01 00:00:02  8.400000e+01  2.242450e-02  2.251000e+01         S1   \n",
      "3 2023-01-01 00:00:03  8.500000e+01  2.338575e-02  2.251000e+01         S1   \n",
      "4 2023-01-01 00:00:04  8.600000e+01  2.306525e-02  2.250000e+01         S1   \n",
      "\n",
      "     session  \n",
      "0  Midterm 1  \n",
      "1  Midterm 1  \n",
      "2  Midterm 1  \n",
      "3  Midterm 1  \n",
      "4  Midterm 1  \n",
      "Preprocessing complete. Processed data shape: (443307, 9)\n",
      "Processed directory exists: True\n",
      "\n",
      "Found 31 processed files:\n",
      "\n",
      "Processed files created successfully!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing check\n",
    "physio_data = load_data(data_dir='data')\n",
    "\n",
    "# Check the loaded data shape\n",
    "print(f\"Loaded data with shape: {physio_data.shape}\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(physio_data.head())\n",
    "# Process the data\n",
    "processed_data = preprocess_data(physio_data)\n",
    "\n",
    "print(f\"Preprocessing complete. Processed data shape: {processed_data.shape}\")\n",
    "# Check if the processed data was created successfully\n",
    "processed_dir = Path('data/processed')\n",
    "\n",
    "# Check if directory exists\n",
    "print(f\"Processed directory exists: {processed_dir.exists()}\")\n",
    "\n",
    "# List processed files\n",
    "if processed_dir.exists():\n",
    "    processed_files = list(processed_dir.glob('*.csv'))\n",
    "    print(f\"\\nFound {len(processed_files)} processed files:\")\n",
    "    \n",
    "    # Group files by type\n",
    "    all_processed = [f for f in processed_files if f.name.startswith('all_')]\n",
    "    subject_files = [f for f in processed_files if not f.name.startswith('all_')]\n",
    "    \n",
    "    # Output details about the files found\n",
    "    if processed_files:\n",
    "        print(f\"\\nProcessed files created successfully!\")\n",
    "    else:\n",
    "        print(\"No processed files were created. Check for errors in the preprocessing function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization\n",
    "\n",
    "Implement the `plot_physiological_signals` function to create visualizations of the physiological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_physiological_signals(data, subject_id, session, output_dir='plots'):\n",
    "    # create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # filter data for specific subject and session\n",
    "    subject_data = data[\n",
    "        (data['subject_id'] == subject_id) & \n",
    "        (data['session'] == session)\n",
    "    ]\n",
    "    \n",
    "    if subject_data.empty:\n",
    "        print(f\"No data found for subject {subject_id} in session {session}\")\n",
    "        return None\n",
    "    \n",
    "    # create figure with subplots for each physiological signal\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    # plot heart rate\n",
    "    if 'heart_rate' in subject_data.columns:\n",
    "        axes[0].plot(subject_data['timestamp'], subject_data['heart_rate'], 'r-')\n",
    "        axes[0].set_title(f'Heart Rate - Subject {subject_id} - {session}')\n",
    "        axes[0].set_ylabel('Heart Rate (BPM)')\n",
    "        axes[0].grid(True)\n",
    "    \n",
    "    # plot EDA\n",
    "    if 'eda' in subject_data.columns:\n",
    "        axes[1].plot(subject_data['timestamp'], subject_data['eda'], 'b-')\n",
    "        axes[1].set_title(f'Electrodermal Activity - Subject {subject_id} - {session}')\n",
    "        axes[1].set_ylabel('EDA (microsiemens)')\n",
    "        axes[1].grid(True)\n",
    "    \n",
    "    # plot skin temperature\n",
    "    if 'temperature' in subject_data.columns:\n",
    "        axes[2].plot(subject_data['timestamp'], subject_data['temperature'], 'g-')\n",
    "        axes[2].set_title(f'Skin Temperature - Subject {subject_id} - {session}')\n",
    "        axes[2].set_ylabel('Temperature (°C)')\n",
    "        axes[2].set_xlabel('Time')\n",
    "        axes[2].grid(True)\n",
    "    \n",
    "    # add title\n",
    "    plt.suptitle(f'Physiological Signals - Subject {subject_id} - {session}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92) \n",
    "    \n",
    "    fig_path = f\"{output_dir}/S{subject_id}_{session}_signals.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Figure saved to {fig_path}\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Subject S1: 3 sessions found\n",
      "Figure saved to plots/SS1_Midterm 1_signals.png\n",
      "Figure saved to plots/SS1_Midterm 2_signals.png\n",
      "Figure saved to plots/SS1_Final_signals.png\n",
      "Processing Subject S10: 3 sessions found\n",
      "Figure saved to plots/SS10_Midterm 1_signals.png\n",
      "Figure saved to plots/SS10_Midterm 2_signals.png\n",
      "Figure saved to plots/SS10_Final_signals.png\n",
      "Processing Subject S2: 3 sessions found\n",
      "Figure saved to plots/SS2_Midterm 1_signals.png\n",
      "Figure saved to plots/SS2_Midterm 2_signals.png\n",
      "Figure saved to plots/SS2_Final_signals.png\n",
      "Processing Subject S3: 3 sessions found\n",
      "Figure saved to plots/SS3_Midterm 1_signals.png\n",
      "Figure saved to plots/SS3_Midterm 2_signals.png\n",
      "Figure saved to plots/SS3_Final_signals.png\n",
      "Processing Subject S4: 3 sessions found\n",
      "Figure saved to plots/SS4_Midterm 1_signals.png\n",
      "Figure saved to plots/SS4_Midterm 2_signals.png\n",
      "Figure saved to plots/SS4_Final_signals.png\n",
      "Processing Subject S5: 3 sessions found\n",
      "Figure saved to plots/SS5_Midterm 1_signals.png\n",
      "Figure saved to plots/SS5_Midterm 2_signals.png\n",
      "Figure saved to plots/SS5_Final_signals.png\n",
      "Processing Subject S6: 3 sessions found\n",
      "Figure saved to plots/SS6_Midterm 1_signals.png\n",
      "Figure saved to plots/SS6_Midterm 2_signals.png\n",
      "Figure saved to plots/SS6_Final_signals.png\n",
      "Processing Subject S7: 3 sessions found\n",
      "Figure saved to plots/SS7_Midterm 1_signals.png\n",
      "Figure saved to plots/SS7_Midterm 2_signals.png\n",
      "Figure saved to plots/SS7_Final_signals.png\n",
      "Processing Subject S8: 3 sessions found\n",
      "Figure saved to plots/SS8_Midterm 1_signals.png\n",
      "Figure saved to plots/SS8_Midterm 2_signals.png\n",
      "Figure saved to plots/SS8_Final_signals.png\n",
      "Processing Subject S9: 3 sessions found\n",
      "Figure saved to plots/SS9_Midterm 1_signals.png\n",
      "Figure saved to plots/SS9_Midterm 2_signals.png\n",
      "Figure saved to plots/SS9_Final_signals.png\n",
      "\n",
      "Plot generation complete:\n",
      "- Successfully created: 30 plots\n",
      "- Failed: 0 plots\n",
      "- Status report saved to: plots/plot_status_report.csv\n"
     ]
    }
   ],
   "source": [
    "# function to check and create visualization plots for all subjects\n",
    "\n",
    "def create_all_subject_plots(processed_data, output_dir='plots'):\n",
    "    # create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # get unique subjects and sessions\n",
    "    subjects = processed_data['subject_id'].unique()\n",
    "    \n",
    "    # track successful plots\n",
    "    successful_plots = 0\n",
    "    failed_plots = 0\n",
    "    \n",
    "    # create a DataFrame to store plot status\n",
    "    plot_status = []\n",
    "    \n",
    "    # loop through all subjects\n",
    "    for subject in subjects:\n",
    "        # get available sessions for this subject\n",
    "        sessions = processed_data[processed_data['subject_id'] == subject]['session'].unique()\n",
    "        \n",
    "        print(f\"Processing Subject {subject}: {len(sessions)} sessions found\")\n",
    "        \n",
    "        # loop through each available session for this subject\n",
    "        for session in sessions:\n",
    "            try:\n",
    "                # create the plot\n",
    "                fig = plot_physiological_signals(processed_data, subject, session, output_dir)\n",
    "                \n",
    "                plt.close(fig)\n",
    "                \n",
    "                successful_plots += 1\n",
    "                status = \"Success\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating plot for Subject {subject}, Session {session}: {e}\")\n",
    "                failed_plots += 1\n",
    "                status = f\"Failed: {str(e)}\"\n",
    "            \n",
    "            # record status\n",
    "            plot_status.append({\n",
    "                'subject_id': subject,\n",
    "                'session': session,\n",
    "                'status': status\n",
    "            })\n",
    "    \n",
    "    # create a summary DataFrame\n",
    "    status_df = pd.DataFrame(plot_status)\n",
    "    \n",
    "    status_df.to_csv(f\"{output_dir}/plot_status_report.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nPlot generation complete:\")\n",
    "    print(f\"- Successfully created: {successful_plots} plots\")\n",
    "    print(f\"- Failed: {failed_plots} plots\")\n",
    "    print(f\"- Status report saved to: {output_dir}/plot_status_report.csv\")\n",
    "    \n",
    "    return successful_plots\n",
    "\n",
    "total_plots = create_all_subject_plots(processed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
